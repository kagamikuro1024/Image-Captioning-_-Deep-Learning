(fer) C:\Users\LAPTOP\Documents\Code\Python>python -u "ImageCaption.py"
2025-12-21 00:36:35.370435: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-21 00:36:43.646029: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
======================================================================
OPTIMIZED CONFIGURATION FOR FLICKR8K
======================================================================
Device: cuda
Batch Size: 32
Epochs: 30
Learning Rate: 1e-04
Weight Decay: 1e-05
Label Smoothing: 0.1
----------------------------------------------------------------------
Embed Size: 256
Hidden Size: 256 (Reduced from 512)
Attention Dim: 256
----------------------------------------------------------------------
Embed Dropout: 0.4
LSTM Dropout: 0.3
Decoder Dropout: 0.5
----------------------------------------------------------------------
Feature shape: (49, 2048)
Gradient Clip: 5.0
======================================================================
Loaded features for 8091 images

Loading captions...
Loaded captions for 8091 images
Cleaning captions...
Building vocabulary...
Vocab size: 8369, Max caption length: 34
Train images: 7281, Test images: 810
Train batches: 1138, Val batches: 127
Total params: 9,146,546, Trainable: 9,146,546
C:\Users\LAPTOP\anaconda3\envs\fer\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(

======================================================================
STARTING TRAINING
======================================================================
Epoch 1/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:19<00:00,  4.39it/s, loss=5.6755] 
Epoch 1/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.47it/s, loss=5.7446] 

Epoch 1/30
Train Loss: 6.1426 | Val Loss: 5.5002
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 5.5002
Epoch 2/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:25<00:00,  4.29it/s, loss=4.9965] 
Epoch 2/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.26it/s, loss=5.3990] 

Epoch 2/30
Train Loss: 5.4697 | Val Loss: 5.1514
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 5.1514
Epoch 3/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:26<00:00,  4.28it/s, loss=5.1955] 
Epoch 3/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.31it/s, loss=5.1626] 

Epoch 3/30
Train Loss: 5.1914 | Val Loss: 4.9389
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.9389
Epoch 4/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:23<00:00,  4.32it/s, loss=4.8974] 
Epoch 4/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.23it/s, loss=5.0336] 

Epoch 4/30
Train Loss: 5.0145 | Val Loss: 4.8107
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.8107
Epoch 5/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:26<00:00,  4.27it/s, loss=5.1030] 
Epoch 5/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:10<00:00, 11.62it/s, loss=4.9215] 

Epoch 5/30
Train Loss: 4.8838 | Val Loss: 4.7111
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.7111
Epoch 6/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [05:58<00:00,  3.17it/s, loss=4.9056] 
Epoch 6/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.49it/s, loss=4.8256] 

Epoch 6/30
Train Loss: 4.7790 | Val Loss: 4.6303
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.6303
Epoch 7/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [06:17<00:00,  3.02it/s, loss=4.8590] 
Epoch 7/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00,  9.80it/s, loss=4.7529] 

Epoch 7/30
Train Loss: 4.6887 | Val Loss: 4.5697
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.5697
Epoch 8/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [06:55<00:00,  2.74it/s, loss=4.5517] 
Epoch 8/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:32<00:00,  3.93it/s, loss=4.7294] 

Epoch 8/30
Train Loss: 4.6171 | Val Loss: 4.5291
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.5291
Epoch 9/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [13:43<00:00,  1.38it/s, loss=4.3270] 
Epoch 9/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:27<00:00,  4.65it/s, loss=4.6335] 

Epoch 9/30
Train Loss: 4.5500 | Val Loss: 4.4784
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.4784
Epoch 10/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [12:26<00:00,  1.52it/s, loss=4.3319] 
Epoch 10/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:29<00:00,  4.34it/s, loss=4.6107] 

Epoch 10/30
Train Loss: 4.4957 | Val Loss: 4.4521
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.4521
Epoch 11/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [11:48<00:00,  1.61it/s, loss=4.5555] 
Epoch 11/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:13<00:00,  9.55it/s, loss=4.6041] 

Epoch 11/30
Train Loss: 4.4434 | Val Loss: 4.4314
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.4314
Epoch 12/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [08:48<00:00,  2.15it/s, loss=4.2532] 
Epoch 12/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:25<00:00,  4.96it/s, loss=4.5630] 

Epoch 12/30
Train Loss: 4.3964 | Val Loss: 4.4015
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.4015
Epoch 13/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [10:46<00:00,  1.76it/s, loss=4.2548] 
Epoch 13/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:27<00:00,  4.58it/s, loss=4.4945]

Epoch 13/30
Train Loss: 4.3540 | Val Loss: 4.3800
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3800
Epoch 14/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [11:30<00:00,  1.65it/s, loss=4.6566] 
Epoch 14/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:25<00:00,  4.90it/s, loss=4.5069] 

Epoch 14/30
Train Loss: 4.3129 | Val Loss: 4.3623
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3623
Epoch 15/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [12:14<00:00,  1.55it/s, loss=4.4212] 
Epoch 15/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:26<00:00,  4.79it/s, loss=4.4549] 

Epoch 15/30
Train Loss: 4.2751 | Val Loss: 4.3633
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 16/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [10:24<00:00,  1.82it/s, loss=4.1719] 
Epoch 16/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:24<00:00,  5.27it/s, loss=4.4299]

Epoch 16/30
Train Loss: 4.2407 | Val Loss: 4.3471
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3471
Epoch 17/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [09:03<00:00,  2.09it/s, loss=4.0800] 
Epoch 17/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:08<00:00, 14.72it/s, loss=4.4370] 

Epoch 17/30
Train Loss: 4.2104 | Val Loss: 4.3258
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3258
Epoch 18/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [09:05<00:00,  2.09it/s, loss=4.1514] 
Epoch 18/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:23<00:00,  5.40it/s, loss=4.3971] 

Epoch 18/30
Train Loss: 4.1779 | Val Loss: 4.3297
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 19/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [10:23<00:00,  1.83it/s, loss=4.0343] 
Epoch 19/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:24<00:00,  5.21it/s, loss=4.4160] 

Epoch 19/30
Train Loss: 4.1488 | Val Loss: 4.3232
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3232
Epoch 20/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [10:41<00:00,  1.77it/s, loss=3.9313] 
Epoch 20/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:10<00:00, 11.87it/s, loss=4.3718] 

Epoch 20/30
Train Loss: 4.1199 | Val Loss: 4.3065
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3065
Epoch 21/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [10:07<00:00,  1.87it/s, loss=4.4254] 
Epoch 21/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:24<00:00,  5.24it/s, loss=4.3693] 

Epoch 21/30
Train Loss: 4.0971 | Val Loss: 4.3046
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3046
Epoch 22/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [05:52<00:00,  3.23it/s, loss=4.1511] 
Epoch 22/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:13<00:00,  9.44it/s, loss=4.4198]

Epoch 22/30
Train Loss: 4.0700 | Val Loss: 4.3075
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 23/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [05:09<00:00,  3.68it/s, loss=4.0059] 
Epoch 23/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.14it/s, loss=4.3513] 

Epoch 23/30
Train Loss: 4.0473 | Val Loss: 4.3041
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.3041
Epoch 24/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [05:06<00:00,  3.72it/s, loss=3.9780] 
Epoch 24/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.00it/s, loss=4.3709] 

Epoch 24/30
Train Loss: 4.0241 | Val Loss: 4.2996
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.2996
Epoch 25/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:47<00:00,  3.96it/s, loss=4.0137] 
Epoch 25/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:08<00:00, 14.15it/s, loss=4.3282] 

Epoch 25/30
Train Loss: 4.0013 | Val Loss: 4.2979
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.2979
Epoch 26/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [03:53<00:00,  4.88it/s, loss=3.8799] 
Epoch 26/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:10<00:00, 12.43it/s, loss=4.3208] 

Epoch 26/30
Train Loss: 3.9775 | Val Loss: 4.3219
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 27/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:49<00:00,  3.93it/s, loss=3.8521] 
Epoch 27/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:09<00:00, 13.26it/s, loss=4.2904]

Epoch 27/30
Train Loss: 3.9579 | Val Loss: 4.2910
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 4.2910
Epoch 28/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:51<00:00,  3.91it/s, loss=4.1103] 
Epoch 28/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.08it/s, loss=4.3927] 

Epoch 28/30
Train Loss: 3.9378 | Val Loss: 4.3019
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 29/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:25<00:00,  4.29it/s, loss=3.9760] 
Epoch 29/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.27it/s, loss=4.3917] 

Epoch 29/30
Train Loss: 3.9158 | Val Loss: 4.3116
LR: 0.000100
No improvement for 2 epoch(s)
Epoch 30/30 [Train]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:22<00:00,  4.34it/s, loss=3.9066] 
Epoch 30/30 [Val]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.15it/s, loss=4.3667] 

Epoch 30/30
Train Loss: 3.8791 | Val Loss: 4.3077
LR: 0.000070
No improvement for 3 epoch(s)

TRAINING COMPLETED

C:\Users\LAPTOP\Documents\Code\Python\ImageCaption.py:957: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(Config.MODEL_SAVE_PATH, map_location=Config.DEVICE)
Loaded best model from epoch 27 with val loss 4.2910
Generating captions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 810/810 [01:00<00:00, 13.45it/s]

BLEU scores:
BLEU-1: 0.4871
BLEU-2: 0.3242
BLEU-3: 0.2132
BLEU-4: 0.1338
Research Evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 810/810 [01:26<00:00,  9.41it/s]

RESEARCH METRICS
==================================================
BLEU-1 (nltk): 0.4871
BLEU-2 (nltk): 0.3242
BLEU-3 (nltk): 0.2132
BLEU-4 (nltk): 0.1338
BLEU-1 (linear BP): 0.4863
BLEU-2 (linear BP): 0.3237
BLEU-3 (linear BP): 0.2128
BLEU-4 (linear BP): 0.1336
METEOR: 0.2789
Avg Pred Len: 7.7975
Avg Ref Len: 7.9222
Len Ratio: 0.9843
==================================================
Research evaluation results: {'BLEU-1 (nltk)': 0.48712572355514544, 'BLEU-2 (nltk)': 0.3242011855783141, 'BLEU-3 (nltk)': 0.21315951290864155, 'BLEU-4 (nltk)': 0.1337630422888166, 'BLEU-1 (linear BP)': 0.4863051984348798, 'BLEU-2 (linear BP)': 0.32368448387182414, 'BLEU-3 (linear BP)': 0.21282816642806668, 'BLEU-4 (linear BP)': 0.13360239363126733, 'METEOR': 0.27891146766439123, 'Avg Pred Len': 7.7975308641975305, 'Avg Ref Len': 7.9222222222222225, 'Len Ratio': 0.9842605578930964}

============================================================
Image ID: 2827964381_408a310809
ACTUAL CAPTIONS:
1. startseq two brown and black dogs wrestle in the long grass endseq
2. startseq two dogs are jumping up at each other in grassy field endseq
3. startseq two dogs jumping on each other endseq
4. startseq two dogs on their hind legs leaning against each other endseq
5. startseq two dogs wrestle in the grass with chain link fence in the background endseq

PREDICTED (greedy):
two dogs are playing in field

PREDICTED (beam size=3):
two dogs play in field
============================================================


============================================================
Image ID: 530661899_94655d7d0e
ACTUAL CAPTIONS:
1. startseq couple walking on dirt road endseq
2. startseq man and women walk atop hill endseq
3. startseq two people backlit with light sky endseq
4. startseq two people walk at sunset endseq
5. startseq two people walk on path as the sun casts shadow towards the camera endseq

PREDICTED (greedy):
two men are standing in front of the mountains

PREDICTED (beam size=3):
two people are standing in front of the mountains
============================================================


============================================================
Image ID: 525863257_053333e612
ACTUAL CAPTIONS:
1. startseq man fly fishes in large river endseq
2. startseq man stands on the edge of the water and holds fishing pole endseq
3. startseq man with tan hat and jacket is fishing in green waters endseq
4. startseq one lone fisherman with his line cast out into the river endseq
5. startseq the man is fishing at the water edge endseq

PREDICTED (greedy):
man is standing in the water

PREDICTED (beam size=3):
man is standing in the water
============================================================


Done.

(fer) C:\Users\LAPTOP\Documents\Code\Python>python -u "ImageCaption.py" --mode resume_train
2025-12-21 04:36:44.436807: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-21 04:36:54.259611: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
======================================================================
LOADING CHECKPOINT FOR RESUME TRAINING
======================================================================
C:\Users\LAPTOP\Documents\Code\Python\ImageCaption.py:992: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(Config.MODEL_SAVE_PATH, map_location=Config.DEVICE)
Found checkpoint from epoch 27
Previous best val loss: 4.2910
Loaded features for 8091 images

Loading captions...
Loaded captions for 8091 images
Cleaning captions...
Loaded vocabulary: 8369 words, max length: 34
Train images: 7281, Test images: 810
Train batches: 1138, Val batches: 127
Model params: 9,146,546
C:\Users\LAPTOP\anaconda3\envs\fer\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
C:\Users\LAPTOP\Documents\Code\Python\ImageCaption.py:473: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=self.config.DEVICE)
✓ Loaded model weights from epoch 27
✓ Loaded optimizer state
✓ Loaded scheduler state
✓ Resuming from epoch 27
✓ Best val loss so far: 4.2910
✓ Epochs without improvement: 0

======================================================================
RESUMING TRAINING
======================================================================
Epoch 1/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:50<00:00,  3.92it/s, loss=3.8877] 
Epoch 1/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.77it/s, loss=3.5647] 

Epoch 1/30
Train Loss: 4.0000 | Val Loss: 3.7107
LR: 0.000100
Model saved to .\content\clean_data_flickr8k\best_model_resnet50_attention_h256_d05.pth
✓ New best model! Val Loss: 3.7107
Epoch 2/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:52<00:00,  3.89it/s, loss=3.9995] 
Epoch 2/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 11.05it/s, loss=3.5496] 

Epoch 2/30
Train Loss: 3.9714 | Val Loss: 3.7280
LR: 0.000100
No improvement for 1 epoch(s)
Epoch 3/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:47<00:00,  3.96it/s, loss=4.3348] 
Epoch 3/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.96it/s, loss=3.5892] 

Epoch 3/30
Train Loss: 3.9474 | Val Loss: 3.7539
LR: 0.000100
No improvement for 2 epoch(s)
Epoch 4/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:57<00:00,  3.83it/s, loss=3.9605] 
Epoch 4/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:11<00:00, 10.93it/s, loss=3.5989] 

Epoch 4/30
Train Loss: 3.9046 | Val Loss: 3.7549
LR: 0.000070
No improvement for 3 epoch(s)
Epoch 5/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:37<00:00,  4.10it/s, loss=3.5528] 
Epoch 5/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:12<00:00, 10.28it/s, loss=3.6004] 

Epoch 5/30
Train Loss: 3.8838 | Val Loss: 3.7707
LR: 0.000070
No improvement for 4 epoch(s)
Epoch 6/30 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1138/1138 [04:51<00:00,  3.91it/s, loss=3.9759] 
Epoch 6/30 [Val]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:06<00:00, 20.68it/s, loss=3.5943] 

Epoch 6/30
Train Loss: 3.8526 | Val Loss: 3.7641
LR: 0.000049
No improvement for 5 epoch(s)
Early stopping after 6 epochs

TRAINING COMPLETED


======================================================================
EVALUATING BEST MODEL
======================================================================
C:\Users\LAPTOP\Documents\Code\Python\ImageCaption.py:1060: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(Config.MODEL_SAVE_PATH, map_location=Config.DEVICE)
Loaded best model from epoch 1 with val loss 3.7107
Generating captions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 810/810 [00:36<00:00, 22.04it/s] 

BLEU scores:
BLEU-1: 0.6027
BLEU-2: 0.4436
BLEU-3: 0.3179
BLEU-4: 0.2139
Research Evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 810/810 [00:39<00:00, 20.48it/s] 

RESEARCH METRICS
==================================================
BLEU-1 (nltk): 0.6027
BLEU-2 (nltk): 0.4436
BLEU-3 (nltk): 0.3179
BLEU-4 (nltk): 0.2139
BLEU-1 (linear BP): 0.6011
BLEU-2 (linear BP): 0.4424
BLEU-3 (linear BP): 0.3170
BLEU-4 (linear BP): 0.2135
METEOR: 0.3594
Avg Pred Len: 7.7889
Avg Ref Len: 7.9519
Len Ratio: 0.9795
==================================================
Research evaluation results: {'BLEU-1 (nltk)': 0.6027164264726471, 'BLEU-2 (nltk)': 0.4436429078494998, 'BLEU-3 (nltk)': 0.31788641015963504, 'BLEU-4 (nltk)': 0.21392330441705948, 'BLEU-1 (linear BP)': 0.6010890812622172, 'BLEU-2 (linear BP)': 0.44244506400533024, 'BLEU-3 (linear BP)': 0.3170281111249437, 'BLEU-4 (linear BP)': 0.21346935052543273, 'METEOR': 0.35936413463570965, 'Avg Pred Len': 7.788888888888889, 'Avg Ref Len': 7.951851851851852, 'Len Ratio': 0.9795062878435026}

============================================================
Image ID: 2768972186_92787cd523
ACTUAL CAPTIONS:
1. startseq big dog is biting smaller dog on the leg endseq
2. startseq dog bites the tail of another dog endseq
3. startseq large brown dog sniffs small white dog behind endseq
4. startseq large brown dog trying to catch small white puppy from behind endseq
5. startseq the large brown dog is sniffing small white dog endseq

PREDICTED (greedy):
brown dog is laying on the ground with brown dog

PREDICTED (beam size=3):
the brown dog is sitting in the sand
============================================================


============================================================
Image ID: 3411393875_a9ff73c67a
ACTUAL CAPTIONS:
1. startseq man in red shirt standing next to woman in black shirt with car in the background endseq
2. startseq man in red shirt that says espana and girl with purple streaks in her hair are smiling endseq
3. startseq man with red spain shirt and woman with purple streaks in her hair endseq
4. startseq the man and lady pose for picture endseq
5. startseq the man is wearing red shirt while the woman standing with him has purple streaks in her hair endseq

PREDICTED (greedy):
man in red shirt is holding her hand in the background

PREDICTED (beam size=3):
man in red shirt is smiling
============================================================


============================================================
Image ID: 3202360797_2084743e90
ACTUAL CAPTIONS:
1. startseq dog is walking in tire track in the snow endseq
2. startseq golden dog is running along tire track that has been carved out in the snow endseq
3. startseq young dog walking through the snow in tire track endseq
4. startseq golden retriever puppy walking through snow endseq
5. startseq the dog is walking in the snow endseq

PREDICTED (greedy):
white dog is running through the snow

PREDICTED (beam size=3):
white dog running through the snow
============================================================


Done.

(fer) C:\Users\LAPTOP\Documents\Code\Python>python -u "ImageCaption.py" --mode research_eval
2025-12-21 05:16:42.426091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-21 05:16:51.949953: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
C:\Users\LAPTOP\Documents\Code\Python\ImageCaption.py:1126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(Config.MODEL_SAVE_PATH, map_location=Config.DEVICE)

Loading captions...
Loaded captions for 8091 images
Cleaning captions...
Research Evaluation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8091/8091 [13:26<00:00, 10.03it/s]

RESEARCH METRICS
==================================================
BLEU-1 (nltk): 0.6123
BLEU-2 (nltk): 0.4580
BLEU-3 (nltk): 0.3340
BLEU-4 (nltk): 0.2325
BLEU-1 (linear BP): 0.6103
BLEU-2 (linear BP): 0.4565
BLEU-3 (linear BP): 0.3330
BLEU-4 (linear BP): 0.2318
METEOR: 0.3696
Avg Pred Len: 7.7011
Avg Ref Len: 7.9424
Len Ratio: 0.9696
==================================================

Done.